<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Automatic Differentiation: Brief Overview</title>
                <meta name="robots" content="noindex" />
                

        <!-- Custom HTML head -->
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

                <link rel="icon" href="favicon.svg">
                        <link rel="shortcut icon" href="favicon.png">
                <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
                <link rel="stylesheet" href="css/print.css" media="print">
        
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
                <link rel="stylesheet" href="fonts/fonts.css">
        
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
                <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
            </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="intro.html"><strong aria-hidden="true">1.</strong> Intro</a></li><li class="chapter-item expanded "><a href="chapter1/chapter_1.html"><strong aria-hidden="true">2.</strong> TODO: What is Automatic Differentiation</a></li><li class="chapter-item expanded "><a href="learningByExample/learning_by_example.html"><strong aria-hidden="true">3.</strong> Learning AD By Example</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="learningByExample/forward_ad.html"><strong aria-hidden="true">3.1.</strong> TODO: Forward Mode AD</a></li><li class="chapter-item expanded "><a href="learningByExample/backward_ad.html"><strong aria-hidden="true">3.2.</strong> TODO: Backward Mode AD</a></li></ol></li><li class="chapter-item expanded "><a href="sources.html"><strong aria-hidden="true">4.</strong> Sources</a></li></ol>            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                                                <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                                            </div>

                    <h1 class="menu-title">Automatic Differentiation: Brief Overview</h1>

                    <div class="right-buttons">
                                                <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                                                                        
                    </div>
                </div>

                                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Deep learning has quickly become a mainstay of how people perceive machine learning as a whole and it has been at the forefront of much research and community effort. These days there are plenty of machine learning libraries and frameworks in a plethora of languages. But someone might still be interested in making their own, some might feel like learning by doing, that by making their own mini framework one might better understand why Pytorch or Tensorflow make the decisions they do. What you learn very quickly is that modern deep learning frameworks do not implement their methods that many neural network articles and tutorials talk about, instead they utilize what some people call <strong>automatic differentiation (AD)</strong>. I was frankly very puzzled what this automatic differentiation was and intimidated by it but I kept coming back and eventually decided to create this book to help both myself and hopefully others in the future to better understand automatic differentiation. </p>
<p>This book serves as a both a scratchpad and a learning resource through my journey of learning a bit of the theory 
and the algorithms that make up automatic differentiation. I want to share some of that learning process in the hopes that it can help
someone else who is also interested in learning AD to read another viewpoint. </p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>The book is split up into a few chapters that first focus on the theory and math behind automatic differentiation. Then it goes over different types of automatic differentiation with a motivating example. </p>
<p>Then I'm going to focus on implementing AD using the Rust programming language by more or less closely following the math to build the intuition of how our AD system will be built.</p>
<h2 id="why-rust"><a class="header" href="#why-rust">Why Rust</a></h2>
<p>I just like programming in Rust. I also like that it feels &quot;high level esc&quot; with lots of abstractions and standard tooling to compile your programs to any platform including WebAssembly. The testing is straightforward and I generally think proper testing also helps alleviate some of Rust's lifetime and ownership pain points.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chapter-1--what-is-automatic-differentiation"><a class="header" href="#chapter-1--what-is-automatic-differentiation">Chapter 1 : What is Automatic Differentiation</a></h1>
<ul>
<li><a href="chapter1/chapter_1.html#what-are-we-trying-to-solve">What are we trying to solve</a></li>
<li><a href="chapter1/chapter_1.html#what-ad-is-not">What AD Is Not</a></li>
<li><a href="chapter1/chapter_1.html#what-ad-is">What AD Is</a></li>
</ul>
<h2 id="what-are-we-trying-to-solve"><a class="header" href="#what-are-we-trying-to-solve">What are we trying to solve</a></h2>
<p>When thinking of what is automatic differentiation it helps to firs think about what exactly this differentiation calculates.
In machine-learning one set of method's sets out to minimize some </p>
<p>TODO</p>
<h2 id="what-ad-is-not"><a class="header" href="#what-ad-is-not">What AD Is Not</a></h2>
<h2 id="what-ad-is"><a class="header" href="#what-ad-is">What AD Is</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learning-by-example"><a class="header" href="#learning-by-example">Learning By Example</a></h1>
<p>We will use an example to motivate the differences between forward and backwards AD. I think that understanding some of the notation here
will clearly help with the intuition of what AD is trying to achieve.</p>
<h2 id="a-motivating-example"><a class="header" href="#a-motivating-example">A Motivating Example</a></h2>
<p>Let's start with an example of a function who's derivative we might want to take. Lets say we have a function of two variables \( x_1 \) and \( x_2 \). let's say we want to take the derivative of this function with respect to (w.r.t) \( x_1 \) and \( x_2 \). Let's define this function \(y\) as follows </p>
<p>\[ y = [sin(x_1/x_2) + x_1/x_2 - exp(x_2)] \times [x_1/x_2 - exp(x_2)] \]</p>
<p>I'm going to introduce two useful ways to represent this problem. One as a <strong>list of intermediate values</strong> and another as a graph representation of such list. First we will introduce a set of intermediate variables \( v_{i} \) where \( i \) can be either a character or a number. Initial input values to our equation are subcripted with letters and all intermediate values are subscripted with numbers. </p>
<ol>
<li>\( v_a = x_1 \)</li>
<li>\( v_b = x_2 \)</li>
<li>\( v_1 = v_a / v_b\)</li>
<li>\( v_2 = sin(v_1) \)</li>
<li>\( v_3 = exp(v_b) \)</li>
<li>\( v_4 = v_1 - v_3 \)</li>
<li>\( v_5 = v_2 + v_4 \)</li>
<li>\( v_6 = v_5 \times v_4 \)</li>
<li>\( y = v_6 \)</li>
</ol>
<p><em>(Do note that the \( \times \) operator here means some sort of multiplication between scalars/matrices with other scalars/matrices. So no cross products)</em></p>
<p>This list above is sometimes called an <strong>execution trace</strong> or a <strong>wengert list</strong> but the most important part is that it separates our function into a set of intermediate steps that makes it easier to reason about how to propagate derivatives. </p>
<p>I think this property is better exemplefied by the graph representation of an execution trace.</p>
<center><img src="learningByExample/images/Example Execution Graph.png">Graph of Execution Trace</center>
<p>To properly understand what this graph means we first must define what each node means.
Each node in this graph primarily represents an <strong>operator</strong> of some sorts. Let's look at an example for node 5 to see what this means.</p>
<center><img src="learningByExample/images/Sample Node V5.png">The node of the value V5 is the addition operator on two input variables</center>
<p>Each node in our graph is some sort of elementary operation. This includes operators like addition, multiplication, or functions like 
trigonometric functions or exponential functions to name a few. A node takes an input depending on the type of function it is. In the case
of the node above:</p>
<ul>
<li>takes two inputs \( v_{2} \) and \( v_{4} \) and adds them together.</li>
<li>knows how to take derivatives w.r.t \( v_{2} \) and \( v_{4} \)</li>
<li>outputs an output value \( v_{5} \)</li>
<li>output value can be used as a final value or an input to any other node</li>
</ul>
<p>The powerful idea comes from the fact that each individual node only needs to know how to take the derivative with respect to its input. With this information the node can share the value of this derivative either forwards to children nodes that take its input \( v_{5} \) or to it's parent nodes, the nodes of \( v_{2} \) and \( v_{4} \). The direction in which this derivative information &quot;flows&quot; is what defines forward AD versus backwards AD. (Maybe it's this idea of &quot;flow&quot; is where TensorFlow got its name from but I haven't checked to make sure)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forward-ad"><a class="header" href="#forward-ad">Forward AD</a></h1>
<ul>
<li><a href="learningByExample/forward_ad.html#execution-trace-approach">Execution Trace Approach</a></li>
<li><a href="learningByExample/forward_ad.html#execution-graph-approach">Execution Graph Approach</a></li>
<li><a href="learningByExample/forward_ad.html#considerations-to-implementing-an-operation-node-for-ad">Considerations to Implementing an Operation Node for AD</a></li>
<li><a href="learningByExample/forward_ad.html#further-reading-computing-directional-derivatices">Further Reading: Computing Directional Derivatices</a></li>
</ul>
<p>Forward AD is the more straightforward implementation of the two and I believe can really help someone with the intuition that makes backward AD make a bit more sense. So let's get started by again looking at our motivating example. </p>
<p>We want to take the derivative of the following function:</p>
<p>\[ y = [sin(x_1/x_2) + x_1/x_2 - exp(x_2)] \times [x_1/x_2 - exp(x_2)] \]</p>
<p>Let's say that we want to calculate the derivative when \( x_1 = 1.5 \) and \( x_2 = 2 \)</p>
<h2 id="execution-trace-approach"><a class="header" href="#execution-trace-approach">Execution Trace Approach</a></h2>
<p>Again looking at the execution trace of our program we get the following </p>
<ol>
<li>\( v_a = x_1 \)</li>
<li>\( v_b = x_2 \)</li>
<li>\( v_1 = v_a / v_b\)</li>
<li>\( v_2 = sin(v_1) \)</li>
<li>\( v_3 = exp(v_b) \)</li>
<li>\( v_4 = v_1 - v_3 \)</li>
<li>\( v_5 = v_2 + v_4 \)</li>
<li>\( v_6 = v_5 \times v_4 \)</li>
<li>\( y = v_6 \)</li>
</ol>
<p>With forward mode AD we now create another execution trace <strong>for each input</strong> into our function. For this example let's take the input \( x_1 \) or the node that outputs \( v_a \). In this execution trace, we first define the derivative of \( v_a \), \( \dot{v_a} = 1\). (I'm using the small dot above v1 to denote its derivative with respect to x_1). Since all the other input's don't have a \( x_1 \) then they are set to 0. </p>
<p>With all subsequent expressions we pass along the previously calculated derivatives. For each node we take the derivative with respect to its input, and to find the derivative w.r.t \( x_1 \) we use the previously calculated derivative. Below is the full trace for \( x_1 \)</p>
<ol>
<li>\( \dot{v_a} = 1 \)</li>
<li>\( \dot{v_b} = 0 \)</li>
<li>\( v_1 = v_a / v_b\)
<ul>
<li>\( \dot{v_1} = (v_b \dot{v_a} - v_a \dot{v_b})  / v_b^2\)</li>
</ul>
</li>
<li>\( v_2 = sin(v_1) \) 
<ul>
<li>\( \dot{v_2} = cos(v_1) \times \dot{v1} \)</li>
</ul>
</li>
<li>\( v_3 = exp(v_b) \)
<ul>
<li>\( \dot{v_3} = exp(v_b) \times \dot{v_b} \)</li>
</ul>
</li>
<li>\( v_4 = v_1 - v_3 \)
<ul>
<li>\( \dot{v_4} = 1 \times \dot{v_1} - 1 \times \dot{v_3} \)</li>
</ul>
</li>
<li>\( v_5 = v_2 + v_4 \)
<ul>
<li>\( \dot{v_5} = 1 \times \dot{v_2} + 1 \times \dot{v_4} \)</li>
</ul>
</li>
<li>\( v_6 = v_5 \times v_4 \)
<ul>
<li>\( v_6 = (v_5 \times \dot{v4}) \times (v_4 \times \dot{v_5}) \)</li>
</ul>
</li>
<li>\( y = v_6 \)
<ul>
<li>\( \dot{y} = \dot{v_6} \)</li>
</ul>
</li>
</ol>
<p>From this we can see from the execution trace where our derivatives come from and how calculating derivatives node by node help save some time.</p>
<!-- ```rust -->
<!-- ```rust
#![allow(unused_variables)]
extern crate autograd_rs;

use autograd_rs::forward_mode::ForwardTensor;

// this is an example function from the paper https://www.cs.princeton.edu/courses/archive/fall18/cos324/files/backprop.pdf
// which is referenced in the book tutorial for forward AD.
fn example_fn(x1 : ForwardTensor, x2 : ForwardTensor) -> ForwardTensor{ 

    ((x1/x2).sin() + x1/x2 - (x2).exp()) * (x1/x2 - x2.exp())
}

fn main() { 
    let mut x1 = ForwardTensor::new(1.5, 1.0, false);
    let mut x2 = ForwardTensor::new(0.5, 0.0, false); 

    let output = example_fn(x1, x2);

    let step_size = 0.001;
    let deriv_estimate = (example_fn(x1 + step_size, x2) - example_fn(x1, x2))/step_size;

    println!("Value: {}, derivative w.r.t x1 {}", output.data, output.deriv);
    println!("Derivative estimate: {}", deriv_estimate.data);

    
    x2.deriv = 1.0; 
    x1.deriv = 0.0; 

    let output_wrt_x2 = example_fn(x1, x2); 

}


```
 -->
<!-- ``` -->
<!-- ```rust
#![allow(unused_variables)]
extern crate autograd_rs;

use autograd_rs::forward_mode::ForwardTensor;

// this is an example function from the paper https://www.cs.princeton.edu/courses/archive/fall18/cos324/files/backprop.pdf
// which is referenced in the book tutorial for forward AD.
fn example_fn(x1 : ForwardTensor, x2 : ForwardTensor) -> ForwardTensor{ 

    ((x1/x2).sin() + x1/x2 - (x2).exp()) * (x1/x2 - x2.exp())
}

fn main() { 
    let mut x1 = ForwardTensor::new(1.5, 1.0, false);
    let mut x2 = ForwardTensor::new(0.5, 0.0, false); 

    let output = example_fn(x1, x2);

    let step_size = 0.001;
    let deriv_estimate = (example_fn(x1 + step_size, x2) - example_fn(x1, x2))/step_size;

    println!("Value: {}, derivative w.r.t x1 {}", output.data, output.deriv);
    println!("Derivative estimate: {}", deriv_estimate.data);

    
    x2.deriv = 1.0; 
    x1.deriv = 0.0; 

    let output_wrt_x2 = example_fn(x1, x2); 

}


```
 -->
<h2 id="execution-graph-approach"><a class="header" href="#execution-graph-approach">Execution Graph Approach</a></h2>
<h2 id="considerations-to-implementing-an-operation-node-for-ad"><a class="header" href="#considerations-to-implementing-an-operation-node-for-ad">Considerations to Implementing an Operation Node for AD</a></h2>
<h2 id="further-reading-computing-directional-derivatices"><a class="header" href="#further-reading-computing-directional-derivatices">Further Reading: Computing Directional Derivatices</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="backward-ad"><a class="header" href="#backward-ad">Backward AD</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sources-for-learning"><a class="header" href="#sources-for-learning">Sources for learning</a></h1>
<p>This is a growing list of the sources I've been using to learn a bit about AD and how to implement it.</p>
<p><a href="https://jmlr.org/papers/volume18/17-468/17-468.pdf">Automatic Differentiation in Machine Learning: a Survey</a></p>
<p><a href="https://www.cs.princeton.edu/courses/archive/fall18/cos324/files/backprop.pdf">COS 324 - Computing Gradients by Backpropagation</a></p>
<p><a href="https://www.cs.toronto.edu/%7Ergrosse/courses/csc321_2018/slides/lec10.pdf">CSC 321 Lecture 10 - Automatic Differentiation</a></p>
<p><a href="https://www.youtube.com/watch?v=wG_nF1awSSY">What is Automatic Differentiation?</a></p>
<p><a href="https://www.youtube.com/watch?v=EEbnprb_YTU&amp;ab_channel=NathanSprague">Reverse Mode Automatic Differentiation</a></p>
<p><a href="https://bilal2vec.github.io/blog/blog/2020/rust-ml-library/">L2: A Rust implementation of backwards automatic differentiation</a></p>
<p><a href="https://towardsdatascience.com/build-your-own-automatic-differentiation-program-6ecd585eec2a">Build Your Own Automatic Differentiation Program</a></p>
<p><a href="https://marksaroufim.medium.com/automatic-differentiation-step-by-step-24240f97a6e6">Automatic Differentiation Step by Step</a></p>
<p><a href="https://dlsys.cs.washington.edu/pdf/lecture4.pdf">CSE599: Lecture 4: Backpropagation and Automatic Differentiation</a></p>
<p><a href="https://cs231n.github.io/convolutional-networks/">CS 231 Convolutional Neural Networks</a></p>
<p><a href="https://github.com/mattjj/autodidact">Autodidact: a pedagogical implementation of Autograd</a></p>
<p><a href="https://github.com/evcu/numpy_autograd">numpy_autograd</a></p>
<h1 id="sources-used-with-this-mdbook"><a class="header" href="#sources-used-with-this-mdbook">Sources used with this mdbook</a></h1>
<p><a href="https://fnordig.de/2019/07/11/mdbook-toc-and-mermaid-preprocessors/">MD book table of contents and diagraming</a></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        
                        
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                
                            </nav>

        </div>

        
        
        
                <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        
                <script src="ace.js" type="text/javascript" charset="utf-8"></script>
        <script src="editor.js" type="text/javascript" charset="utf-8"></script>
        <script src="mode-rust.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-dawn.js" type="text/javascript" charset="utf-8"></script>
        <script src="theme-tomorrow_night.js" type="text/javascript" charset="utf-8"></script>
        
                <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
                        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
                
    </body>
</html>
